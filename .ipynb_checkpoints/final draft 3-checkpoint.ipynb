{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import stats\n",
      "import statsmodels.api as sm\n",
      "import scipy.stats as ss\n",
      "from functools import partial\n",
      "from pandas import Series, DataFrame, Panel\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.linear_model import Ridge\n",
      "from numba import jit, int32, int64, float32, float64 \n",
      "\n",
      "import multiprocessing\n",
      "%matplotlib inline\n",
      "%precision 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "u'%.4f'"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rpy2.ipython\n",
      "from rpy2.robjects.packages import importr\n",
      "p1=importr('leaps')\n",
      "p2=importr('stats')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named rpy2.ipython",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-88c54fa9925e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'load_ext rpy2.ipython'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimportr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'leaps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimportr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stats'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yuchen/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yuchen/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yuchen/anaconda/lib/python2.7/site-packages/IPython/core/magics/extension.pyc\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
        "\u001b[0;32m/Users/yuchen/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yuchen/anaconda/lib/python2.7/site-packages/IPython/core/magics/extension.pyc\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yuchen/anaconda/lib/python2.7/site-packages/IPython/core/extensions.pyc\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named rpy2.ipython"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Background"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "  \n",
      "   I selected the Fast FSR Variable Selection research paper by Yujun Wu, Leonard A. Stefanski and Dennis D. Boos in 2009. Many variable selection procedures have been developed in the literature for linear regression models. A new and general approach, the False Selection Rate (FSR) method, to control variable selection is applicable to a broader class of regression models. The algorithm Fast FSR is a type of forward selection method and sequentially selects variables with fixed False Selection Rate (Usually target rate 0.05). \n",
      "   \n",
      "   The earlier verison of FSR variable selection method by Wu, Boos, and Stefanski (2007) requires\n",
      "the generation of the phony explanatory variables and the rate at which they enter a variable selection procedure is monitored as a function of a tuning parameter like \u03b1-to-enter of forward selection. This rate function is then used to estimate the appropriate tuning parameter so that the average rate that uninformative variables enter selected models is controlled to be \u03b30, usually 0.05. However, the Fast FSR developed in this paper requires no phony variable generation, but achieves the same result. Bascially, it depends on this mathematical formula to select variables:\n",
      "     $$ K(\\gamma_0) = max \\{i :\\tilde{p_i} <= \\frac{(1 + S)* \\gamma_0}{k_{T} - S}, and, \\tilde{p_i} <= \\alpha_{max}\\}$$\n",
      "   \n",
      "   Fast FSR has competitive advantages among model selection method. It can give the parsimony model when the number of variables are bigger than the number of observations. Although lasso regression performs well in high dimension model selection, it is not competitive based on some criteria, where Fast FSR can compensate these disadvantages. Fast FSR has lower False Selection Rate than Lasso regression and have similar Model Error as lasso, which will be shown in the simulation study part. In addition, I implemented the optimization of the Fast FSR, Fast FSR bagging which is useful when a large of high correlated predictors are suspected in real case. Normal forward selection\u2019s and lasso prediction performance can degrade with higly correlated predictors. \n",
      "   \n",
      " - Flow of this project\n",
      "     - Implement the Fast FSR and bagging Fast FSR\n",
      "     - Two unit tests on the forward selection and get_fsr functions\n",
      "     - Profile the performance of the algorithm: Pure python and vectorized python of function are written and the vectorized version improved the speed twice\n",
      "     - High performance programming : Parellel programming by using multiple core. The result improves the speed twice compared the vectorized version.\n",
      "     - Application and comparison: Compare the lasso and Fast FSR on the four simulated data set models. Based on the two criteria, False selection rate and Model error. Lasso and Fast FSR has similar Model error, however, the False Selection rate is lower in Fast FSR\n",
      "     - Method optimization: Bagging Fast FSR: more applicable for the general data set: highly correlated predictors are suspected.\n",
      "     - Reproducible analysis: I applied the Fast FSR to the NCAA data which is provided by the \"Boos-Stefanski Variable Selection Home\"\n",
      "     http://www4.stat.ncsu.edu/~boos/var.select/ncaa.data.orig.txt.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Implement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "  - Implement main functions: Fast FSR\n",
      "  - Description of fsr_fast_vectorized:\n",
      "     - Input observation array and reponse y\n",
      "     - Based on the forward selection function and selection rule as follows, variables are selected\n",
      "     $$ K(\\gamma_0) = max \\{i :\\tilde{p_i} <= \\frac{(1 + S)* \\gamma_0}{k_{T} - S}, and, \\tilde{p_i} <= \\alpha_{max}\\}$$\n",
      "     - Returned linear regression model on the selected variables, model size, name of the selected variables and false selection rate.\n",
      "     "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fsr_fast_vectorized(x,y):\n",
      "    gam0=0.05\n",
      "    digits = 4\n",
      "    m = x.shape[1]\n",
      "    n = x.shape[0]\n",
      "    if(m >= n): \n",
      "        m1=n-5  \n",
      "    else: \n",
      "        m1=m \n",
      "    vm = range(m1)\n",
      "    pvm = np.zeros(m1)  # to create pvm below\n",
      "    out_x = p1.regsubsets(x,y,method=\"forward\")  # foward selection by r function\n",
      "    rss = out_x[9]\n",
      "    nn = out_x[26][0]\n",
      "    n_rss = np.array(range(len(rss)-1))\n",
      "    q = [(rss[i]-rss[i+1])*(nn-i-2)/rss[i+1] for i in n_rss]\n",
      "    rvf = ss.f(1,nn-n_rss-2)\n",
      "    orig = np.array(1-rvf.cdf(q))    \n",
      "    for i in range(m1):  # sequentially get max of pvalues\n",
      "        pvm[i] = np.max(orig[0:i+1])\n",
      "    alpha = [0]+pvm\n",
      "    S = np.zeros(len(alpha)) # Include number of true entering in orig.\n",
      "    for ia in range(1,len(alpha)):   #loop through alpha values for S=size and size of models at alpha[ia], S[1]=0                 \n",
      "        S[ia] = sum([pvm[i] <= alpha[ia] for i in range(len(pvm))])        \n",
      "    ghat = (m-S)*alpha/(1+S)    \n",
      "    alphamax = alpha[np.argmax(ghat)] # Got index of largest ghat\n",
      "    ind = np.zeros(len(ghat))\n",
      "    ind = np.where((ghat<gam0)&(alpha <=alphamax),1,0)\n",
      "    Sind = S[np.max(np.where(np.array(ind)>0))] # model size with ghat just below gam0\n",
      "    alphahat_fast = (1+Sind)*gam0/(m-Sind) \n",
      "    size1=np.sum(np.array(pvm)<=alphahat_fast)+1 # size of model including intercept\n",
      "    x=x[list(x.columns.values[list((np.array(out_x[7])-2)[1:size1])])]\n",
      "    x=sm.add_constant(x) # linear regression on the selected variables\n",
      "    if(size1>1): \n",
      "        x_ind=(np.array(out_x[7])-1)[1:size1]\n",
      "    else:\n",
      "        x_ind=0\n",
      "    if (size1==1):\n",
      "        mod = np.mean(y)\n",
      "    else:\n",
      "        mod = sm.OLS(y, x).fit()\n",
      " \n",
      "    return mod,size1-1,x_ind,alphahat_fast"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FSRR_vectorized (target,method,model,n):\n",
      "    l =[]\n",
      "    for i in range(n):\n",
      "        x = np.array(np.random.normal(1, 1, 21*1500).reshape(1500,21))\n",
      "        if (model==1):\n",
      "            y = x[:,0]\n",
      "        if (model==2):\n",
      "            b = np.array([9,4,1,9,4,1])\n",
      "            y = np.dot(x[:,0:6],b)\n",
      "        if (model==3):\n",
      "            b = np.array([25,16,9,4,1,25,16,9,4,1])\n",
      "            y = np.dot(x[:,0:10],b)\n",
      "        if (model==4):\n",
      "            b = np.array([45,36,25,16,9,4,1,45,36,25,16,9,4,1])\n",
      "            y = np.dot(x[:,0:14],b)\n",
      "        if (model==5):\n",
      "            x[:,2] = 2*x[:,3]\n",
      "            x[:,4] = 3*x[:,5]\n",
      "            b = np.array([9,4,1,9,4,1])\n",
      "            y = np.dot(x[:,0:6],b)\n",
      "        quad = (x[:,0:20])**2\n",
      "        x = np.concatenate((x,quad),axis=1)\n",
      "        x = pd.DataFrame(x)\n",
      "        m = method(x,y)\n",
      "        L = get_fsr(target,method,x,y)\n",
      "        l.append(L)\n",
      "    return l\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Unit Test"
     ]
<<<<<<< HEAD
    }
   ],
   "source": [
    "# Simulate the data set under model 1\n",
    "target =[1]\n",
    "n = int(100)\n",
    "\n",
    "print \"LASSO FSR is\",pi_multiprocessing1(target,lasso_fit,1,n)\n",
    "print \"FAST FSR is\",pi_multiprocessing1(target,fsr_fast_vectorized,1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO FSR is 0.541538461538\n",
      "FAST FSR is 0.199567099567\n"
     ]
    }
   ],
   "source": [
    "# Simulate the data under model 2 6–8 and 13–15\n",
    "n = int(100)\n",
    "target = [0,1,2,3,4,5]\n",
    "\n",
    "print \"LASSO FSR is\",pi_multiprocessing1(target,lasso_fit,2,n)\n",
    "print \"FAST FSR is\",pi_multiprocessing1(target,fsr_fast_vectorized,2,n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
=======
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - Two Unit Tests on functions forward_selection and get_fsr\n",
      " \n",
      "   - Unit test of forward_selection: The true linear relationship should be y = b + 10*x1+ 200*x2+ 0.5*x3 + 0.01*x4 + 0.001*x5. This forward selection function should select variables from the most related to less related. Thus, the returned result should be 1,3,2,4,5,6 where 1 denotes the intercept"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def foward_selection(x,y):\n",
      "    out_x = p1.regsubsets(x,y,method=\"forward\") \n",
      "    rss = out_x[9]\n",
      "    nn = out_x[26][0]\n",
      "    r_7 = out_x[7]\n",
      "    q = [(rss[i]-rss[i+1])*(nn-i-2)/rss[i+1] for i in range(len(rss)-1)]\n",
      "    rvf = [ ss.f(1,nn-i-2)  for i in range(len(rss)-1)]\n",
      "    orig =  [1-rvf[i].cdf(q[i]) for i in range(len(rss)-1)]\n",
      "    return orig,r_7\n",
      "x = pd.DataFrame(np.random.normal(1, 1,5*1000).reshape(1000,5))\n",
      "b = np.array([10,200,0.5,0.01,0.001])\n",
      "y = np.dot(x,b)\n",
      "print foward_selection(x,y)[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'p1' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-4fb1504805a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mfoward_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-4-4fb1504805a0>\u001b[0m in \u001b[0;36mfoward_selection\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfoward_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mout_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregsubsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mr_7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'p1' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
>>>>>>> 681aa6498ef2b0679460fa5659efbd3474f4f943
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Get the size and alphahat of FAST FSR"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Profiling: Naive Version and Vectoried Verison"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " - First two naive version functions are written. Then I profiling these functions and vectorized two functions. The speed of the vectorized verision improves twice as much as the pure python. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! pip install --pre line-profiler &> /dev/null\n",
      "! pip install psutil &> /dev/null\n",
      "! pip install memory_profiler &> /dev/null"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Naive_Fast_FSR(x,y):\n",
      "    gam0=0.05\n",
      "    digits = 4\n",
      "    pl = 1\n",
      "    m = x.shape[1]\n",
      "    n = x.shape[0]\n",
      "    if(m >= n): \n",
      "        m1=n-5  \n",
      "    else: \n",
      "        m1=m \n",
      "    vm = range(m1)\n",
      "  # if only partially named columns corrects for no colnames\n",
      "    pvm = [0] * m1 \n",
      "    out_x = p1.regsubsets(x,y,method=\"forward\")  \n",
      "    rss = out_x[9]\n",
      "    nn = out_x[26][0]\n",
      "    q = [(rss[i]-rss[i+1])*(nn-i-2)/rss[i+1] for i in range(len(rss)-1)]\n",
      "    rvf = [ ss.f(1,nn-i-2)  for i in range(len(rss)-1)]\n",
      "    orig =  [1-rvf[i].cdf(q[i]) for i in range(len(rss)-1)]\n",
      "# sequential max of pvalues\n",
      "    for i in range(m1):\n",
      "        pvm[i] = max(orig[0:i+1])  \n",
      "    alpha = [0]+pvm\n",
      "    ng = len(alpha)\n",
      " # will contain num. of true entering in orig\n",
      "    S = [0] * ng\n",
      " # loop through alpha values for S=size                        \n",
      "    for ia in range(1,ng):                   \n",
      "        S[ia] = sum([pvm[i] <= alpha[ia] for i in range(len(pvm))])        # size of models at alpha[ia], S[1]=0\n",
      "    ghat = [(m-S[i])*alpha[i]/(1+S[i]) for i in range(len(alpha))]              # gammahat_ER \n",
      "    alphamax = alpha[np.argmax(ghat)]\n",
      "    ind = [0]*len(ghat)\n",
      "    ind = [ 1 if ghat[i]<gam0 and alpha[i]<=alphamax else 0 for i in range(len(ghat))]\n",
      "    Sind = S[np.max(np.where(np.array(ind)>0))]\n",
      "    alphahat_fast = (1+Sind)*gam0/(m-Sind)\n",
      "    size1=np.sum(np.array(pvm)<=alphahat_fast)+1\n",
      "    x=x[list(x.columns.values[list((np.array(out_x[7])-2)[1:size1])])]\n",
      "    x=sm.add_constant(x)\n",
      "    if(size1>1): \n",
      "        x_ind=(np.array(out_x[7])-1)[1:size1]\n",
      "    else:\n",
      "        x_ind=0\n",
      "    if (size1==1):\n",
      "        mod = np.mean(y)\n",
      "    else:\n",
      "        mod = sm.OLS(y, x).fit()\n",
      "    return mod,size1-1,x_ind,alphahat_fast"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Naive_FSRR (target,method,model,n):\n",
      "    l =[]\n",
      "    for i in range(n):\n",
      "        x = pd.DataFrame(np.random.normal(1, 1, 21*1500).reshape(1500,21))\n",
      "        if (model==1):\n",
      "            y = x.ix[:,1]\n",
      "        if (model==2):\n",
      "            y = 9*x.ix[:,0]+4*x.ix[:,1]+x.ix[:,2]+9*x.ix[:,3]+4*x.ix[:,4]+x.ix[:,5]\n",
      "        if (model==3):\n",
      "            y = 25*x.ix[:,0]+16*x.ix[:,1]+9*x.ix[:,2]+4*x.ix[:,3]+1*x.ix[:,4]+25*x.ix[:,5]+16*x.ix[:,6]+9*x.ix[:,7]+4*x.ix[:,8]+1*x.ix[:,9]\n",
      "        if (model==4):\n",
      "            y = 45*x.ix[:,0]+36*x.ix[:,1]+25*x.ix[:,2]+16*x.ix[:,3]+9*x.ix[:,4]+4*x.ix[:,5]+x.ix[:,6]+45*x.ix[:,7]+36*x.ix[:,8]+25*x.ix[:,9]+16*x.ix[:,10]+9*x.ix[:,11]+4*x.ix[:,12]+x.ix[:,13]\n",
      "        if (model==5):\n",
      "            x.ix[:,2] = 2*x.ix[:,3]\n",
      "            x.ix[:,4] = 3*x.ix[:,5]\n",
      "            y = 9*x.ix[:,5]+4*x.ix[:,6]+x.ix[:,7]+9*x.ix[:,12]+4*x.ix[:,13]+x.ix[:,14]\n",
      "        quad = (x.ix[:,0:20])**2\n",
      "        x = np.concatenate((x,quad),axis=1)\n",
      "        x = pd.DataFrame(x)\n",
      "        m = method(x,y)\n",
      "        L = get_fsr(target,method,x,y)\n",
      "        l.append(L)\n",
      "    return l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Application: Real Data and Simulation Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- NCCA DATA "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('ncaa.data2.txt',delim_whitespace=True)\n",
      "x = df.ix[:,0:19]\n",
      "y = df.ix[:,19]\n",
      "fsr_fast_vectorized(x,y)[0].summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.811</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.800</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   75.50</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Thu, 30 Apr 2015</td> <th>  Prob (F-statistic):</th> <td>2.49e-30</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>11:41:18</td>     <th>  Log-Likelihood:    </th> <td> -315.88</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>    94</td>      <th>  AIC:               </th> <td>   643.8</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>    88</td>      <th>  BIC:               </th> <td>   659.0</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>const</th> <td>  -42.1069</td> <td>    8.990</td> <td>   -4.684</td> <td> 0.000</td> <td>  -59.972   -24.242</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>x2</th>    <td>    3.4714</td> <td>    0.467</td> <td>    7.428</td> <td> 0.000</td> <td>    2.543     4.400</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>x3</th>    <td>    0.2391</td> <td>    0.076</td> <td>    3.163</td> <td> 0.002</td> <td>    0.089     0.389</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>x5</th>    <td>    0.2787</td> <td>    0.078</td> <td>    3.582</td> <td> 0.001</td> <td>    0.124     0.433</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>x4</th>    <td>    0.6770</td> <td>    0.195</td> <td>    3.475</td> <td> 0.001</td> <td>    0.290     1.064</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>x7</th>    <td>   -2.5913</td> <td>    0.832</td> <td>   -3.115</td> <td> 0.002</td> <td>   -4.245    -0.938</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td> 5.624</td> <th>  Durbin-Watson:     </th> <td>   1.718</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.060</td> <th>  Jarque-Bera (JB):  </th> <td>   3.905</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 0.351</td> <th>  Prob(JB):          </th> <td>   0.142</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 2.290</td> <th>  Cond. No.          </th> <td>    620.</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.811\n",
        "Model:                            OLS   Adj. R-squared:                  0.800\n",
        "Method:                 Least Squares   F-statistic:                     75.50\n",
        "Date:                Thu, 30 Apr 2015   Prob (F-statistic):           2.49e-30\n",
        "Time:                        11:41:18   Log-Likelihood:                -315.88\n",
        "No. Observations:                  94   AIC:                             643.8\n",
        "Df Residuals:                      88   BIC:                             659.0\n",
        "Df Model:                           5                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const        -42.1069      8.990     -4.684      0.000       -59.972   -24.242\n",
        "x2             3.4714      0.467      7.428      0.000         2.543     4.400\n",
        "x3             0.2391      0.076      3.163      0.002         0.089     0.389\n",
        "x5             0.2787      0.078      3.582      0.001         0.124     0.433\n",
        "x4             0.6770      0.195      3.475      0.001         0.290     1.064\n",
        "x7            -2.5913      0.832     -3.115      0.002        -4.245    -0.938\n",
        "==============================================================================\n",
        "Omnibus:                        5.624   Durbin-Watson:                   1.718\n",
        "Prob(Omnibus):                  0.060   Jarque-Bera (JB):                3.905\n",
        "Skew:                           0.351   Prob(JB):                        0.142\n",
        "Kurtosis:                       2.290   Cond. No.                         620.\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Biology Data in the paper"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Method Comparsion: Lasso and Fast FSR on simulated model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Comparsion among lasso, fast fsr, ridge and forward selectino with BIC based on two criteria: Model Error Ratio \n",
      "  and False Selection Rate by the simulated data \n",
      "- In this simulation study, I simulated 100 data points with 42 variables. Four models are simulated: H1: all variables are zeros. H2: 6 variables are non-zeros at variables 6\u20138 and 13\u201315 with values (9,4,1). H3: 10 variables are non-zeros at variables 5\u20139 and 12\u201316 with values (25,16,9,4,1). H4: 14 variables are non-zeros at variables 4\u201310 and 11\u201317 with value (49, 36, 25, 16, 9, 4, 1)\n",
      "- Plot the ME and FSR comparison plot for four models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Lasso Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lasso_fit (x,y):\n",
      "    alpha =0.5\n",
      "    lasso = Lasso(alpha=alpha, tol=0.001)\n",
      "    y_coef_lasso = lasso.fit(x, y).coef_\n",
      "    lasso_index = np.where(y_coef_lasso != 0)[0]+1\n",
      "    return lasso_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- assesment of model: False selection rate on Four Simulated Models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Calculate the False Selection Rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_fsr (target,method,x,y):  \n",
      "        m = method(x,y)\n",
      "        if (len(m) == 4 and m[1]==0):\n",
      "             m = []\n",
      "        if (len(m) == 4 and m[1]!=0):\n",
      "             m = m[2]\n",
      "        I = set(target)&set(m)\n",
      "        L = (len(m)-len(I))/(1.0+len(m))\n",
      "        return L"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- unit test for get_fsr\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def ME (method_coef,x,y,n):\n",
      "    me=[]\n",
      "    for i in range(n):\n",
      "        me.append(np.sum((np.dot(method_coef,x.transpose())-y)**2)/150.0)\n",
      "        i = i + 1\n",
      "    return me\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Parall pragramming"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pi_multiprocessing1(target,method,model,n):\n",
      "    \"\"\"Split a job of length n into num_procs pieces.\"\"\"\n",
      "    import multiprocessing\n",
      "    m = multiprocessing.cpu_count()\n",
      "    pool = multiprocessing.Pool(m)\n",
      "    mapfunc = partial(FSRR_vectorized,target,method,model)\n",
      "    results = pool.map(mapfunc,[n/m]*m)\n",
      "    pool.close()\n",
      "    return np.mean(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simulate the data set under model 1\n",
      "target =[1]\n",
      "n = int(100)\n",
      "\n",
      "print \"LASSO FSR is\",pi_multiprocessing1(target,lasso_fit,1,n)\n",
      "print \"FAST FSR is\",pi_multiprocessing1(target,fsr_fast_vectorized,1,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LASSO FSR is 0.42\n",
        "FAST FSR is 0.0953333333333\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simulate the data under model 2 6\u20138 and 13\u201315\n",
      "n = int(100)\n",
      "target = [0,1,2,3,4,5]\n",
      "\n",
      "print \"LASSO FSR is\",pi_multiprocessing1(target,lasso_fit,2,n)\n",
      "print \"FAST FSR is\",pi_multiprocessing1(target,fsr_fast_vectorized,2,n)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LASSO FSR is 0.545559440559\n",
        "FAST FSR is 0.210142857143\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = int(100)\n",
      "target = [6,7,8,13,14,15]\n",
      "model=2\n",
      "Naive_FSRR (target,fsr_fast_vectorized,model,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "0.1271"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simulate the data under model 3 5\u20139 and 12\u201316 \n",
      "n = int(100)\n",
      "target = [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "print \"LASSO FSR is\",pi_multiprocessing1(target,lasso_fit,3,n)\n",
      "print \"FAST FSR is\",pi_multiprocessing1(target,fsr_fast_vectorized,3,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " LASSO FSR is 0.528030075188\n",
        "FAST FSR is 0.13285048285\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simulate the data under model 4  4\u201310 and 11\u201317 \n",
      "\n",
      "n = int(100)\n",
      "target = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
      "print \"LASSO FSR is\",pi_multiprocessing1(target,lasso_fit,4,n)\n",
      "print \"FAST FSR is\",pi_multiprocessing1(target,fsr_fast_vectorized,4,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LASSO FSR is 0.515649516512\n",
        "FAST FSR is 0.108661850705\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Profiling: Naive Version, Cytonized Version and Parallization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Naive Verision:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def Naive_Fast_FSR(x,y):\n",
      "    gam0=0.05\n",
      "    digits = 4\n",
      "    pl = 1\n",
      "    m = x.shape[1]\n",
      "    n = x.shape[0]\n",
      "    if(m >= n): \n",
      "        m1=n-5  \n",
      "    else: \n",
      "        m1=m \n",
      "    vm = range(m1)\n",
      "  # if only partially named columns corrects for no colnames\n",
      "    pvm = [0] * m1 \n",
      "    out_x = p1.regsubsets(x,y,method=\"forward\")  \n",
      "    rss = out_x[9]\n",
      "    nn = out_x[26][0]\n",
      "    q = [(rss[i]-rss[i+1])*(nn-i-2)/rss[i+1] for i in range(len(rss)-1)]\n",
      "    rvf = [ ss.f(1,nn-i-2)  for i in range(len(rss)-1)]\n",
      "    orig =  [1-rvf[i].cdf(q[i]) for i in range(len(rss)-1)]\n",
      "# sequential max of pvalues\n",
      "    for i in range(m1):\n",
      "        pvm[i] = max(orig[0:i+1])  \n",
      "    alpha = [0]+pvm\n",
      "    ng = len(alpha)\n",
      " # will contain num. of true entering in orig\n",
      "    S = [0] * ng\n",
      " # loop through alpha values for S=size                        \n",
      "    for ia in range(1,ng):                   \n",
      "        S[ia] = sum([pvm[i] <= alpha[ia] for i in range(len(pvm))])        # size of models at alpha[ia], S[1]=0\n",
      "    ghat = [(m-S[i])*alpha[i]/(1+S[i]) for i in range(len(alpha))]              # gammahat_ER \n",
      "    alphamax = alpha[np.argmax(ghat)]\n",
      "    ind = [0]*len(ghat)\n",
      "    ind = [ 1 if ghat[i]<gam0 and alpha[i]<=alphamax else 0 for i in range(len(ghat))]\n",
      "    Sind = S[np.max(np.where(np.array(ind)>0))]\n",
      "    alphahat_fast = (1+Sind)*gam0/(m-Sind)\n",
      "    size1=np.sum(np.array(pvm)<=alphahat_fast)+1\n",
      "    x=x[list(x.columns.values[list((np.array(out_x[7])-2)[1:size1])])]\n",
      "    x=sm.add_constant(x)\n",
      "    if(size1>1): \n",
      "        x_ind=(np.array(out_x[7])-1)[1:size1]\n",
      "    else:\n",
      "        x_ind=0\n",
      "    if (size1==1):\n",
      "        mod = np.mean(y)\n",
      "    else:\n",
      "        mod = sm.OLS(y, x).fit()\n",
      "    return mod,size1-1,x_ind,alphahat_fast"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Naive_FSRR (target,method,model,n):\n",
      "    l =[]\n",
      "    for i in range(n):\n",
      "        x = pd.DataFrame(np.random.normal(1, 1, 21*1500).reshape(1500,21))\n",
      "        if (model==1):\n",
      "            y = x.ix[:,1]\n",
      "        if (model==2):\n",
      "            y = 9*x.ix[:,0]+4*x.ix[:,1]+x.ix[:,2]+9*x.ix[:,3]+4*x.ix[:,4]+x.ix[:,5]\n",
      "        if (model==3):\n",
      "            y = 25*x.ix[:,0]+16*x.ix[:,1]+9*x.ix[:,2]+4*x.ix[:,3]+1*x.ix[:,4]+25*x.ix[:,5]+16*x.ix[:,6]+9*x.ix[:,7]+4*x.ix[:,8]+1*x.ix[:,9]\n",
      "        if (model==4):\n",
      "            y = 45*x.ix[:,0]+36*x.ix[:,1]+25*x.ix[:,2]+16*x.ix[:,3]+9*x.ix[:,4]+4*x.ix[:,5]+x.ix[:,6]+45*x.ix[:,7]+36*x.ix[:,8]+25*x.ix[:,9]+16*x.ix[:,10]+9*x.ix[:,11]+4*x.ix[:,12]+x.ix[:,13]\n",
      "        if (model==5):\n",
      "            x.ix[:,2] = 2*x.ix[:,3]\n",
      "            x.ix[:,4] = 3*x.ix[:,5]\n",
      "            y = 9*x.ix[:,5]+4*x.ix[:,6]+x.ix[:,7]+9*x.ix[:,12]+4*x.ix[:,13]+x.ix[:,14]\n",
      "        quad = (x.ix[:,0:20])**2\n",
      "        x = np.concatenate((x,quad),axis=1)\n",
      "        x = pd.DataFrame(x)\n",
      "        m = method(x,y)\n",
      "        L = get_fsr(target,method,x,y)\n",
      "        l.append(L)\n",
      "    return l\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FSRR_vectorized (target,method,model,n):\n",
      "    l =[]\n",
      "    for i in range(n):\n",
      "        x = np.array(np.random.normal(1, 1, 21*1500).reshape(1500,21))\n",
      "        if (model==1):\n",
      "            y = x[:,0]\n",
      "        if (model==2):\n",
      "            b = np.array([9,4,1,9,4,1])\n",
      "            y = np.dot(x[:,0:6],b)\n",
      "        if (model==3):\n",
      "            b = np.array([25,16,9,4,1,25,16,9,4,1])\n",
      "            y = np.dot(x[:,0:10],b)\n",
      "        if (model==4):\n",
      "            b = np.array([45,36,25,16,9,4,1,45,36,25,16,9,4,1])\n",
      "            y = np.dot(x[:,0:14],b)\n",
      "        if (model==5):\n",
      "            x[:,2] = 2*x[:,3]\n",
      "            x[:,4] = 3*x[:,5]\n",
      "            b = np.array([9,4,1,9,4,1])\n",
      "            y = np.dot(x[:,0:6],b)\n",
      "        quad = (x[:,0:20])**2\n",
      "        x = np.concatenate((x,quad),axis=1)\n",
      "        x = pd.DataFrame(x)\n",
      "        m = method(x,y)\n",
      "        L = get_fsr(target,method,x,y)\n",
      "        l.append(L)\n",
      "    return l\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Profile the Naive verison and the Vectorized version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext line_profiler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The line_profiler extension is already loaded. To reload it, use:\n",
        "  %reload_ext line_profiler\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lprun -f fsr_fast_vectorized fsr_fast_vectorized(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%lprun -f Naive_Fast_FSR Naive_Fast_FSR(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%lprun -f Naive_FSRR Naive_FSRR(target,Naive_Fast_FSR,model,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lprun -f FSRR_vectorized FSRR_vectorized(target,fsr_fast_vectorized,model,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%timeit C_False_Selection_Rate([],C_Fast_FSR,1,n)\n",
      "#%timeit pi_multiprocessing1([],C_Fast_FSR,1,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FSRR_vectorized([4,5,6,7,8,9,10,11,12,13,14,15,16],fsr_fast_vectorized,4,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[0.2000,\n",
        " 0.2000,\n",
        " 0.2941,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2941,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.3333,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.3333,\n",
        " 0.2941,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2941,\n",
        " 0.2500,\n",
        " 0.1875,\n",
        " 0.2941,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.1875,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2353,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.3158,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2941,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2941,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2941,\n",
        " 0.2941,\n",
        " 0.2000,\n",
        " 0.2941,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.1875,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.3333,\n",
        " 0.2941,\n",
        " 0.2000,\n",
        " 0.2941,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.3333,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2941,\n",
        " 0.2000,\n",
        " 0.3333,\n",
        " 0.3333,\n",
        " 0.2500,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.2500,\n",
        " 0.2353,\n",
        " 0.2000,\n",
        " 0.2000,\n",
        " 0.2353,\n",
        " 0.2000,\n",
        " 0.2500,\n",
        " 0.3684,\n",
        " 0.2000,\n",
        " 0.2778,\n",
        " 0.2500,\n",
        " 0.2941,\n",
        " 0.2000]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n =100\n",
      "%timeit Naive_FSRR([4,5,6,7,8,9,10,11,12,13,14,15,16],Naive_Fast_FSR,4,n)\n",
      "%timeit FSRR_vectorized([4,5,6,7,8,9,10,11,12,13,14,15,16],fsr_fast_vectorized,4,n)\n",
      "#%timeit pi_multiprocessing1([4,5,6,7,8,9,10,11,12,13,14,15,16],C_Fast_FSR,4,n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Algorithm Improvement : Bagging Fast FSR"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def bag_fsr(x,y,B,gam0,fsr_fast,digits):\n",
      "    m = x.shape[1]\n",
      "    n = x.shape[0]\n",
      "    hold = np.zeros((B,m+1))      # holds coefficients\n",
      "    hold = pd.DataFrame(hold)\n",
      "    alphahat = [0] * B                    # holds alphahats\n",
      "    size = [0] * B\n",
      "    for i in range(B):\n",
      "        index = np.random.choice(n, n)\n",
      "        out = fsr_fast(x.ix[index,:],y.ix[index])\n",
      "        if out[1]>0:\n",
      "            hold.iloc[i,out[2]] = np.array(out[0].params)[1:(len(out[2])+1)]\n",
      "        hold.iloc[i,0] = out[0].params[0]\n",
      "        alphahat[i] = out[3]\n",
      "        size[i] = out[1]\n",
      "    hold[np.isnan(hold)]=0\n",
      "    para_av = np.mean(hold,0)\n",
      "    para_sd = [0]*(m+1)\n",
      "    para_sd = np.var(hold,0)**0.5\n",
      "    amean = np.mean(alphahat)\n",
      "    sizem = np.mean(size)\n",
      "    pred = np.matrix(x)*np.transpose(np.matrix(para_av[1:]))+para_av[0]\n",
      "    return para_av,para_sd,pred,amean,sizem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
