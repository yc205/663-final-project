{
 "metadata": {
  "name": "",
  "signature": "sha256:608d0b4932c6e6d94003ff27a654a96f53c06cea07b8070fb1640e8b27359b7d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "u'%.4f'"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Wrote the source data\n",
      "data = pd.read_csv('ncaa.data2.txt',delim_whitespace=True)\n",
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>x1</th>\n",
        "      <th>x2</th>\n",
        "      <th>x3</th>\n",
        "      <th>x4</th>\n",
        "      <th>x5</th>\n",
        "      <th>x6</th>\n",
        "      <th>x7</th>\n",
        "      <th>x8</th>\n",
        "      <th>x9</th>\n",
        "      <th>x10</th>\n",
        "      <th>x11</th>\n",
        "      <th>x12</th>\n",
        "      <th>x13</th>\n",
        "      <th>x14</th>\n",
        "      <th>x15</th>\n",
        "      <th>x16</th>\n",
        "      <th>x17</th>\n",
        "      <th>x18</th>\n",
        "      <th>x19</th>\n",
        "      <th>y</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 13</td>\n",
        "      <td> 17</td>\n",
        "      <td>  9</td>\n",
        "      <td> 15</td>\n",
        "      <td> 28.0</td>\n",
        "      <td>  0</td>\n",
        "      <td>-1.14045</td>\n",
        "      <td> 3.660</td>\n",
        "      <td> 4.490</td>\n",
        "      <td>  3409</td>\n",
        "      <td> 65.8</td>\n",
        "      <td> 18</td>\n",
        "      <td> 81</td>\n",
        "      <td> 42.2</td>\n",
        "      <td> 660000</td>\n",
        "      <td> 77</td>\n",
        "      <td> 100</td>\n",
        "      <td> 59</td>\n",
        "      <td>  1</td>\n",
        "      <td> 35.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 28</td>\n",
        "      <td> 20</td>\n",
        "      <td> 32</td>\n",
        "      <td> 18</td>\n",
        "      <td> 18.4</td>\n",
        "      <td> 18</td>\n",
        "      <td>-0.13719</td>\n",
        "      <td> 2.594</td>\n",
        "      <td> 3.610</td>\n",
        "      <td>  7258</td>\n",
        "      <td> 66.3</td>\n",
        "      <td> 17</td>\n",
        "      <td> 82</td>\n",
        "      <td> 40.5</td>\n",
        "      <td> 150555</td>\n",
        "      <td> 88</td>\n",
        "      <td>  94</td>\n",
        "      <td> 41</td>\n",
        "      <td> 25</td>\n",
        "      <td> 57.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 32</td>\n",
        "      <td> 20</td>\n",
        "      <td> 20</td>\n",
        "      <td> 20</td>\n",
        "      <td> 34.8</td>\n",
        "      <td> 18</td>\n",
        "      <td> 1.55358</td>\n",
        "      <td> 2.060</td>\n",
        "      <td> 4.930</td>\n",
        "      <td>  6405</td>\n",
        "      <td> 75.0</td>\n",
        "      <td> 19</td>\n",
        "      <td> 71</td>\n",
        "      <td> 46.5</td>\n",
        "      <td> 415400</td>\n",
        "      <td> 94</td>\n",
        "      <td>  81</td>\n",
        "      <td> 25</td>\n",
        "      <td> 36</td>\n",
        "      <td> 51.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 32</td>\n",
        "      <td> 21</td>\n",
        "      <td> 24</td>\n",
        "      <td> 21</td>\n",
        "      <td> 14.5</td>\n",
        "      <td> 20</td>\n",
        "      <td> 2.05712</td>\n",
        "      <td> 2.887</td>\n",
        "      <td> 3.876</td>\n",
        "      <td> 18294</td>\n",
        "      <td> 66.0</td>\n",
        "      <td> 16</td>\n",
        "      <td> 84</td>\n",
        "      <td> 42.2</td>\n",
        "      <td> 211000</td>\n",
        "      <td> 93</td>\n",
        "      <td>  88</td>\n",
        "      <td> 26</td>\n",
        "      <td> 13</td>\n",
        "      <td> 41.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 24</td>\n",
        "      <td> 20</td>\n",
        "      <td> 16</td>\n",
        "      <td> 20</td>\n",
        "      <td> 21.8</td>\n",
        "      <td> 13</td>\n",
        "      <td>-0.77082</td>\n",
        "      <td> 2.565</td>\n",
        "      <td> 4.960</td>\n",
        "      <td>  8259</td>\n",
        "      <td> 63.5</td>\n",
        "      <td> 16</td>\n",
        "      <td> 91</td>\n",
        "      <td> 41.2</td>\n",
        "      <td>  44000</td>\n",
        "      <td> 90</td>\n",
        "      <td>  92</td>\n",
        "      <td> 32</td>\n",
        "      <td> 31</td>\n",
        "      <td> 65.7</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "   x1  x2  x3  x4    x5  x6       x7     x8     x9    x10   x11  x12  x13  \\\n",
        "0  13  17   9  15  28.0   0 -1.14045  3.660  4.490   3409  65.8   18   81   \n",
        "1  28  20  32  18  18.4  18 -0.13719  2.594  3.610   7258  66.3   17   82   \n",
        "2  32  20  20  20  34.8  18  1.55358  2.060  4.930   6405  75.0   19   71   \n",
        "3  32  21  24  21  14.5  20  2.05712  2.887  3.876  18294  66.0   16   84   \n",
        "4  24  20  16  20  21.8  13 -0.77082  2.565  4.960   8259  63.5   16   91   \n",
        "\n",
        "    x14     x15  x16  x17  x18  x19     y  \n",
        "0  42.2  660000   77  100   59    1  35.0  \n",
        "1  40.5  150555   88   94   41   25  57.0  \n",
        "2  46.5  415400   94   81   25   36  51.3  \n",
        "3  42.2  211000   93   88   26   13  41.3  \n",
        "4  41.2   44000   90   92   32   31  65.7  "
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = data.ix[:,0:19]\n",
      "y = data.ix[:,19]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rpy2.ipython\n",
      "from rpy2.robjects.packages import importr\n",
      "stats = importr('leaps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The rpy2.ipython extension is already loaded. To reload it, use:\n",
        "  %reload_ext rpy2.ipython\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Pseudocode/outline of algorithm\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Step1: Got rid of NA's in the data set \n",
      "\n",
      "- Step2: Wrote the forward selection method for the linear regression. The returned list includes the p-values in each iteration and the order of the varaibles entered\n",
      "    - First, fit one predictor a time on the response y and choose the predictors which has the smallest p-value\n",
      "    - Second, fit this predictor and one left predictor on the response y and choose the predictor which leads to the smalles pvalue. Up to now, we have two selected variables\n",
      "    - Finally, after some steps, all the variables going to be entered bigger than 0.05, the forward selection method stops.\n",
      "- Step3: Create the pvm vector which saves the max p_value according to the following formula and get the $ \\hat{\\gamma}$\n",
      "    - First, caculate the pv.orig based on the following the formula \n",
      "    - Second, select the max_pvalue based on the formula \n",
      "      $\\tilde{p_1} < \\tilde{p_2} < \\tilde{p_3}...< \\tilde{p_k}$\n",
      "    - Third, built the alpha vector as (0,pmv)\n",
      "    - Fourth, create a S vector which stands for model size based on the formula\n",
      "      $$ S = max \\{i : \\tilde{p_i} < \\alpha \\} $$\n",
      "    - Calculate the\n",
      "      $ \\hat{\\gamma} = \\frac{(m-S)* \\alpha}{1 + S}\\\\$  \n",
      "      \n",
      "- Step4: Determine the model size and returned the model\n",
      "    \n",
      "   $${\\hat{\\gamma} < \\hat{\\gamma_0}, \\alpha <= \\alpha_{max}}$$\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Unite Test:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "  1. Whether there is missing data in the data set\n",
      "  2. Test whether the result implmemented by this algorithm has the same answer with the paper"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}